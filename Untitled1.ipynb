{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import seaborn as snb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, predicted ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, predicted,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, predicted )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_churn_data = pd.read_csv('traindata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = pd.read_csv('telecom_churn_data.csv')\n",
    "scaled_churn_data['Unnamed: 0'].head()\n",
    "scaled_churn_data = scaled_churn_data.drop(['Unnamed: 0'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = scaled_churn_data['churn']\n",
    "scaled_churn_data = scaled_churn_data.drop(['churn'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='randomized', random_state=42)\n",
    "pca.fit(scaled_churn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that 57 components are sufficient to explain 95%  of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#however we can take incremental PCA to get the values of data corresponding to new components\n",
    "pca_final = IncrementalPCA(n_components=57)\n",
    "churn_data_pca = pca_final.fit_transform(scaled_churn_data)\n",
    "churn_data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mat = np.corrcoef(churn_data_pca.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat_nodiag = correlation_mat - np.diagflat(correlation_mat.diagonal())\n",
    "print(np.max(corrmat_nodiag))\n",
    "print(np.min(corrmat_nodiag))\n",
    "correlation_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation is almost close to zero.So now we are good to start with modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first lets get our hands dirty with simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "scaled_churn_data_test = pd.read_csv('testdata.csv')\n",
    "churn_test = scaled_churn_data_test['churn']\n",
    "scaled_churn_data_test = scaled_churn_data_test.drop(['churn'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_churn_data_test = scaled_churn_data_test.drop(['Unnamed: 0'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_test_data = pca_final.transform(scaled_churn_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "model_pca = learner_pca.fit(churn_data_pca,churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_train = model_pca.predict_proba(churn_data_pca)[:,1]\n",
    "churn_pred = pd.Series(pred_prob_train).map(lambda x:1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(metrics.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the confusion matrix again \n",
    "confusion = metrics.confusion_matrix(churn,churn_pred )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(metrics.confusion_matrix)\n",
    "metrics.accuracy_score(churn, churn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check sensitivity and specificity of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = confusion[1,1]/(confusion[1,1]+confusion[1,0])\n",
    "specificity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "print(sensitivity)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(churn, pred_prob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in [0.5,0.45,0.4,0.35,0.3,0.25,0.2]:\n",
    "    churn_pred = pd.Series(pred_prob_train).map(lambda x:1 if x>cutoff else 0)\n",
    "    confusion = metrics.confusion_matrix(churn,churn_pred )\n",
    "    print(str(cutoff)+\":\")\n",
    "    print(confusion)\n",
    "    sensitivity = confusion[1,1]/(confusion[1,1]+confusion[1,0])\n",
    "    specificity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "    print(\"Sensitivity:\")\n",
    "    print(sensitivity)\n",
    "    print(\"Specificity:\")\n",
    "    print(specificity)\n",
    "    print(\"Accuracy\")\n",
    "    print(metrics.accuracy_score(churn, churn_pred))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model we can pick cuttoff as 0.45 as sensitivity is more important here.It gives almost 86% sensitivity and decent accuracy of 77%.Its important to identify churners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that model has pretty good sensitivity,specificity and good accuracy.However sensitivity is more important\n",
    "in our model.However this is in case of training data.Lets check for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_test = model_pca.predict_proba(churn_test_data)[:,1]\n",
    "churn_pred_test = pd.Series(pred_prob_test).map(lambda x:1 if x>0.45 else 0)\n",
    "confusion = metrics.confusion_matrix(churn_test,churn_pred_test )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = confusion[1,1]/(confusion[1,1]+confusion[1,0])\n",
    "specificity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "metrics.accuracy_score(churn_test, churn_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to be doing good job on test data as well with sensitivity ,specificity and accuracy being very much\n",
    "in par with training data set.As of now regularization is not required as there is no significant difference between the\n",
    "metrics of train and test performances,no sign of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take another model SVM and evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(C=10,kernel = 'linear',class_weight='balanced')\n",
    "svc_model.fit(churn_data_pca,churn)\n",
    "pred_svm = svc_model.predict(churn_data_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(churn,pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5,shuffle = True,random_state = 4)\n",
    "hyperparamers = [{'gamma' :[0.001,0.01,0.05,0.1,0.5,10,30,50,100],'C':[10,15,20,25,30,50,100]}]\n",
    "model_svc = SVC(kernel = \"rbf\",class_weight='balanced')  \n",
    "model_grid_search = GridSearchCV(estimator = model_svc,param_grid = hyperparameters,scoring = 'accuracy',fold = folds,verbose = 1,return_train_score = True)\n",
    "model_grid_search.fit(churn_data_pca,churn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
